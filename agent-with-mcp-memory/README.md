# Интенсивный курс: Создание ИИ-агентов с помощью инструментов с открытым исходным кодом

Этот проект представляет собой практический интенсивный курс по созданию ИИ-агентов с использованием технологий с полностью открытым исходным кодом! Вы узнаете:

- Что такое ИИ-агент
- Подключение агентов к инструментам
- Обзор MCP (Multi-Component Protocol)
- Замена инструментов серверами MCP
- Настройка наблюдаемости и отслеживания

Все концепции демонстрируются с помощью реального, работоспособного кода.

### Посмотрите этот учебник на YouTube
<a href="https://youtu.be/R6sMAZaTCR4">
<img src="assets/thumbnail.jpeg" alt="Посмотрите этот учебник на YouTube" width="550"/>
</a>

## Что такое агент искусственного интеллекта?

ИИ-агент использует LLM в качестве своего мозга, имеет память для сохранения контекста и может выполнять реальные действия с помощью инструментов (например, просматривать веб-страницы, запускать код и т. д.).

Короче говоря: он думает, помнит и действует.

## Технический стек

- [CrewAI](https://github.com/crewAIInc) — создание агентов, готовых к MCP
- [Zep Graphiti](https://github.com/getzep/graphiti) — добавление памяти, подобной человеческой
- [CometML Opik](https://github.com/comet-ml/opik) — наблюдаемость и отслеживание
- 100% открытый исходный код!

## Обзор системы

Вот как работает система:

1. Пользователь отправляет запрос
2. Помощник запускает веб-поиск через MCP
3. Запрос + результаты поступают в диспетчер памяти
4. Диспетчер памяти сохраняет контекст в Graphiti
5. Агент ответа формирует окончательный ответ

---

### Настройка

- **Настройка Ollama:**
1. Установите Ollama, следуя официальным инструкциям для вашей ОС:

**Для macOS:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Для Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Для Windows:**
Загрузите и установите с [официального сайта Ollama](https://ollama.com/download)

2. Загрузите необходимую модель:
```bash
ollama pull llama3.2
```

Вы должны увидеть ответ от модели. Если вы получили какие-либо ошибки, проверьте, что Ollama работает, с помощью:


- **Добавьте все необходимые ключи:**

Создайте новый файл `.env` в корневом каталоге проекта, используя `.env.example` в качестве шаблона. Скопируйте файл-пример и введите свои API-ключи и секретные ключи по мере необходимости.

```bash
cp .env.example .env
# Затем отредактируйте .env, чтобы добавить свои ключи.
```

- **Установите зависимости:**

Выполните следующую команду в корневом каталоге проекта, чтобы установить все необходимые зависимости:

```bash
uv sync
```

#### Запустите серверы MCP:

- **Запустите сервер Linkup:**

[Получите ключи API Linkup здесь](https://www.linkup.so/)

Выполните следующую команду в корневом каталоге проекта:

```bash
python server.py
```

- **Запустите сервер Graphiti MCP:**

Это предназначено только для продвинутых пользователей, вы можете изучить все основы, используя только сервер Linkup MCP.

Следуйте инструкциям в [Graphiti MCP README](https://github.com/xenon007/ai-engineering-hub/blob/main/graphiti-mcp/README.md)
